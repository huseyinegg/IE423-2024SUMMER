{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sx5QJoLysR-S"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/huseyinegg/IE423-2024SUMMER/blob/main/M.HuseyinBeyribey_IE423_TASK5.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knPjBMZjsUWb"
      },
      "source": [
        "# Initialize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJi-cNyMsmLa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DcdxYgDswhO",
        "outputId": "7f068230-8a48-4822-d739-06ee5ac439ef"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>1x1</th>\n",
              "      <th>1x2</th>\n",
              "      <th>1x3</th>\n",
              "      <th>1x4</th>\n",
              "      <th>1x5</th>\n",
              "      <th>1x6</th>\n",
              "      <th>1x7</th>\n",
              "      <th>1x8</th>\n",
              "      <th>1x9</th>\n",
              "      <th>...</th>\n",
              "      <th>28x19</th>\n",
              "      <th>28x20</th>\n",
              "      <th>28x21</th>\n",
              "      <th>28x22</th>\n",
              "      <th>28x23</th>\n",
              "      <th>28x24</th>\n",
              "      <th>28x25</th>\n",
              "      <th>28x26</th>\n",
              "      <th>28x27</th>\n",
              "      <th>28x28</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>119</td>\n",
              "      <td>114</td>\n",
              "      <td>130</td>\n",
              "      <td>76</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
              "0      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
              "1      0    0    0    0    0    0    1    0    0    0  ...    119    114   \n",
              "2      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
              "3      3    0    0    0    0    0    0    0    0   33  ...      0      0   \n",
              "4      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
              "\n",
              "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
              "0      0      0      0      0      0      0      0      0  \n",
              "1    130     76      0      0      0      0      0      0  \n",
              "2      1      0      0      0      0      0      0      0  \n",
              "3      0      0      0      0      0      0      0      0  \n",
              "4      0      0      0      0      0      0      0      0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fashion_mnist_data = pd.read_csv('data/mnist_fashion_train.csv')\n",
        "fashion_mnist_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhFpncy5s72v",
        "outputId": "4c6a754b-b496-4440-a19f-8f01504278c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 60000 entries, 0 to 59999\n",
            "Columns: 785 entries, label to 28x28\n",
            "dtypes: int64(785)\n",
            "memory usage: 359.3 MB\n"
          ]
        }
      ],
      "source": [
        "fashion_mnist_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKu4iieTuG4k",
        "outputId": "318c401c-41d1-4a67-e8e6-bb5f40856729"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "label    0\n",
              "1x1      0\n",
              "1x2      0\n",
              "1x3      0\n",
              "1x4      0\n",
              "        ..\n",
              "28x24    0\n",
              "28x25    0\n",
              "28x26    0\n",
              "28x27    0\n",
              "28x28    0\n",
              "Length: 785, dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fashion_mnist_data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QN09gZa_uPiR"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import scale\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y = fashion_mnist_data['label']\n",
        "X = scale(fashion_mnist_data.drop(['label'], axis=1))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr_kmQEBuc-a"
      },
      "source": [
        "## Analyze Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "O1q2fT3ZueKQ",
        "outputId": "94c0b9ea-962f-46b5-cfa6-c44e6f051709"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Handwriting \t\t\t\t Label\n",
            "AxesImage(shape=(28, 28)) \t\t 9\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print('Handwriting', '\\t\\t\\t\\t', 'Label')\n",
        "print(plt.imshow(X[0].reshape((28,28))), '\\t\\t', y[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "xFOurms2vkj5",
        "outputId": "30222dd8-6cfd-4ea8-bbbe-b35899d79ac4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: ylabel='count'>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.countplot(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whPRunDcv909"
      },
      "source": [
        "##Â Predict Digit from Handwriting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_bY_w0lwNdd"
      },
      "source": [
        "At task 4, I have applied several classification models. Such as Logistic Regression, Naive Bayes Classifier, K-Nearest Neighbor (KNN), Support Vector Machines, Gradient Boosting, BalancedRandom Forest, XGBoost. Now I will combine all of them into one code, and apply for classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpmvMHtPb3tW",
        "outputId": "78305d48-1ea2-4174-e71c-a50a2423c19f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Logistic Regression ---\n",
            "Cross-Validation Scores: [0.83791667 0.83135417 0.83604167 0.84447917 0.84125   ]\n",
            "Mean CV Score: 0.8382083333333334\n",
            "Accuracy: 0.8428333333333333\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.81      0.80      1166\n",
            "           1       0.95      0.97      0.96      1213\n",
            "           2       0.76      0.73      0.74      1232\n",
            "           3       0.85      0.86      0.85      1209\n",
            "           4       0.72      0.79      0.76      1159\n",
            "           5       0.93      0.92      0.93      1217\n",
            "           6       0.62      0.57      0.60      1178\n",
            "           7       0.91      0.93      0.92      1215\n",
            "           8       0.93      0.91      0.92      1178\n",
            "           9       0.94      0.93      0.93      1233\n",
            "\n",
            "    accuracy                           0.84     12000\n",
            "   macro avg       0.84      0.84      0.84     12000\n",
            "weighted avg       0.84      0.84      0.84     12000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 939    8   30   59    3    2  112    1   12    0]\n",
            " [   4 1179    5   18    2    0    4    1    0    0]\n",
            " [  22    7  896    9  170    1  121    2    4    0]\n",
            " [  30   26   14 1038   49    0   37    0   14    1]\n",
            " [   3    1   97   35  917    4   94    1    7    0]\n",
            " [   1    3    1    1    1 1122    1   50    6   31]\n",
            " [ 177    9  126   50  112    1  670    0   33    0]\n",
            " [   0    0    0    0    0   39    0 1132    5   39]\n",
            " [  12    5    8   14   12    8   33    7 1073    6]\n",
            " [   0    0    1    0    0   30    1   52    1 1148]]\n",
            "AUC Score: 0.9823389457900318\n",
            "\n",
            "--- Naive Bayes ---\n",
            "Cross-Validation Scores: [0.57375    0.56395833 0.55947917 0.57645833 0.6021875 ]\n",
            "Mean CV Score: 0.5751666666666666\n",
            "Accuracy: 0.5695\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.58      0.68      1166\n",
            "           1       0.59      0.95      0.73      1213\n",
            "           2       0.57      0.28      0.37      1232\n",
            "           3       0.44      0.48      0.46      1209\n",
            "           4       0.35      0.75      0.48      1159\n",
            "           5       0.90      0.26      0.40      1217\n",
            "           6       0.29      0.04      0.07      1178\n",
            "           7       0.49      0.98      0.65      1215\n",
            "           8       0.85      0.74      0.79      1178\n",
            "           9       0.91      0.64      0.75      1233\n",
            "\n",
            "    accuracy                           0.57     12000\n",
            "   macro avg       0.62      0.57      0.54     12000\n",
            "weighted avg       0.62      0.57      0.54     12000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 674   93   33  196  125    0   20    0   25    0]\n",
            " [   2 1153   12   33    3    0    8    0    2    0]\n",
            " [   4   22  343   61  725    0   43    0   34    0]\n",
            " [  10  560    5  582   38    0   12    0    2    0]\n",
            " [   1   63   47  159  875    0    2    0   12    0]\n",
            " [   0    1    2    2    0  312    7  821   11   61]\n",
            " [ 139   57  136  187  557    0   50    0   52    0]\n",
            " [   0    0    0    0    0    6    0 1189    3   17]\n",
            " [   1    6   19  102  144    7   29    4  866    0]\n",
            " [   0    0    2    1    1   22    2  407    8  790]]\n",
            "AUC Score: 0.8866473364016987\n",
            "\n",
            "--- KNN ---\n",
            "Cross-Validation Scores: [0.8503125  0.84875    0.85072917 0.85270833 0.850625  ]\n",
            "Mean CV Score: 0.850625\n",
            "Accuracy: 0.8548333333333333\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.88      0.81      1166\n",
            "           1       0.99      0.97      0.98      1213\n",
            "           2       0.75      0.78      0.77      1232\n",
            "           3       0.90      0.87      0.88      1209\n",
            "           4       0.75      0.79      0.77      1159\n",
            "           5       0.99      0.84      0.91      1217\n",
            "           6       0.67      0.58      0.62      1178\n",
            "           7       0.88      0.96      0.92      1215\n",
            "           8       0.99      0.92      0.95      1178\n",
            "           9       0.90      0.96      0.93      1233\n",
            "\n",
            "    accuracy                           0.85     12000\n",
            "   macro avg       0.86      0.85      0.85     12000\n",
            "weighted avg       0.86      0.85      0.85     12000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1028    1   21   25    2    0   87    0    2    0]\n",
            " [   9 1174    4   19    2    0    5    0    0    0]\n",
            " [  28    1  963   14  143    0   82    1    0    0]\n",
            " [  51   13   15 1046   57    0   23    0    3    1]\n",
            " [   3    0  115   30  911    0   99    0    1    0]\n",
            " [   1    0    2    1    0 1018    4  104    1   86]\n",
            " [ 234    2  144   18   93    0  678    0    9    0]\n",
            " [   0    0    0    0    0    3    0 1163    0   49]\n",
            " [   9    0   18    9   11    2   28    9 1089    3]\n",
            " [   0    0    0    0    0    4    1   40    0 1188]]\n",
            "AUC Score: 0.9683621158401223\n",
            "\n",
            "--- SVM ---\n",
            "Cross-Validation Scores: [0.88854167 0.88947917 0.8859375  0.88979167 0.88770833]\n",
            "Mean CV Score: 0.8882916666666667\n",
            "Accuracy: 0.8893333333333333\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.86      0.84      1166\n",
            "           1       0.99      0.98      0.98      1213\n",
            "           2       0.83      0.81      0.82      1232\n",
            "           3       0.88      0.90      0.89      1209\n",
            "           4       0.80      0.85      0.83      1159\n",
            "           5       0.97      0.95      0.96      1217\n",
            "           6       0.75      0.66      0.70      1178\n",
            "           7       0.93      0.96      0.95      1215\n",
            "           8       0.94      0.97      0.96      1178\n",
            "           9       0.96      0.94      0.95      1233\n",
            "\n",
            "    accuracy                           0.89     12000\n",
            "   macro avg       0.89      0.89      0.89     12000\n",
            "weighted avg       0.89      0.89      0.89     12000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1008    0   18   44    1    0   85    0   10    0]\n",
            " [   5 1184    1   16    1    0    3    0    3    0]\n",
            " [  14    0  995   13  120    0   83    0    7    0]\n",
            " [  24    8    7 1092   47    0   25    0    6    0]\n",
            " [   1    0   74   34  990    0   57    0    3    0]\n",
            " [   0    0    0    1    0 1155    0   39    7   15]\n",
            " [ 177    1  101   27   71    0  776    0   25    0]\n",
            " [   0    0    0    0    0   16    0 1167    2   30]\n",
            " [   3    0    5    9    5    2   12    2 1140    0]\n",
            " [   0    0    0    0    0   19    0   44    5 1165]]\n",
            "AUC Score: 0.9914782198437321\n",
            "\n",
            "--- Gradient Boosting ---\n",
            "Cross-Validation Scores: [0.8684375  0.87197917 0.86677083 0.87791667 0.87572917]\n",
            "Mean CV Score: 0.8721666666666665\n",
            "Accuracy: 0.874\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.83      0.82      1166\n",
            "           1       0.99      0.97      0.98      1213\n",
            "           2       0.80      0.81      0.80      1232\n",
            "           3       0.87      0.89      0.88      1209\n",
            "           4       0.76      0.82      0.79      1159\n",
            "           5       0.98      0.95      0.96      1217\n",
            "           6       0.70      0.61      0.65      1178\n",
            "           7       0.92      0.95      0.94      1215\n",
            "           8       0.96      0.95      0.96      1178\n",
            "           9       0.95      0.94      0.95      1233\n",
            "\n",
            "    accuracy                           0.87     12000\n",
            "   macro avg       0.87      0.87      0.87     12000\n",
            "weighted avg       0.87      0.87      0.87     12000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 972    3   18   54    1    1  108    0    9    0]\n",
            " [   9 1182    3   17    1    0    1    0    0    0]\n",
            " [  15    1  992   11  131    1   73    0    8    0]\n",
            " [  28    6   12 1072   50    0   38    0    3    0]\n",
            " [   2    0   92   40  955    0   65    0    5    0]\n",
            " [   1    0    0    0    0 1152    0   39    4   21]\n",
            " [ 188    3  117   28  108    0  720    0   14    0]\n",
            " [   0    0    0    0    0   12    0 1156    2   45]\n",
            " [   0    1    3    7   11    6   25    3 1122    0]\n",
            " [   0    0    0    0    0    9    0   57    2 1165]]\n",
            "AUC Score: 0.9895500277675229\n",
            "\n",
            "--- Random Forest ---\n",
            "Cross-Validation Scores: [0.874375   0.88072917 0.8759375  0.8825     0.87802083]\n",
            "Mean CV Score: 0.8783125\n",
            "Accuracy: 0.8825833333333334\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.86      0.83      1166\n",
            "           1       0.99      0.97      0.98      1213\n",
            "           2       0.80      0.81      0.80      1232\n",
            "           3       0.88      0.91      0.90      1209\n",
            "           4       0.77      0.86      0.81      1159\n",
            "           5       0.97      0.96      0.97      1217\n",
            "           6       0.74      0.60      0.66      1178\n",
            "           7       0.93      0.94      0.94      1215\n",
            "           8       0.97      0.97      0.97      1178\n",
            "           9       0.94      0.95      0.95      1233\n",
            "\n",
            "    accuracy                           0.88     12000\n",
            "   macro avg       0.88      0.88      0.88     12000\n",
            "weighted avg       0.88      0.88      0.88     12000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1001    0   19   50    2    1   85    0    8    0]\n",
            " [   5 1173    1   27    0    0    7    0    0    0]\n",
            " [   5    1  992   11  144    0   71    0    8    0]\n",
            " [  21    3   14 1103   37    0   26    0    5    0]\n",
            " [   1    1   79   34  993    0   49    0    2    0]\n",
            " [   0    0    0    0    0 1172    0   32    1   12]\n",
            " [ 199    1  128   25  110    0  701    0   14    0]\n",
            " [   0    0    0    0    0   13    0 1146    1   55]\n",
            " [   2    0    4    5    6    1   13    4 1142    1]\n",
            " [   0    0    0    0    0   17    0   47    1 1168]]\n",
            "AUC Score: 0.9902691492979866\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/huseyin/.virtualenvs/Pythonnn3/skit_learn_env/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [04:10:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/huseyin/.virtualenvs/Pythonnn3/skit_learn_env/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [04:12:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/huseyin/.virtualenvs/Pythonnn3/skit_learn_env/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [04:15:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/huseyin/.virtualenvs/Pythonnn3/skit_learn_env/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [04:17:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/huseyin/.virtualenvs/Pythonnn3/skit_learn_env/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [04:20:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/huseyin/.virtualenvs/Pythonnn3/skit_learn_env/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [04:23:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- XGBoost ---\n",
            "Cross-Validation Scores: [0.89760417 0.895625   0.89791667 0.90083333 0.89989583]\n",
            "Mean CV Score: 0.898375\n",
            "Accuracy: 0.9043333333333333\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.85      1166\n",
            "           1       0.99      0.98      0.99      1213\n",
            "           2       0.84      0.84      0.84      1232\n",
            "           3       0.91      0.91      0.91      1209\n",
            "           4       0.83      0.87      0.85      1159\n",
            "           5       0.98      0.97      0.98      1217\n",
            "           6       0.76      0.69      0.72      1178\n",
            "           7       0.95      0.96      0.95      1215\n",
            "           8       0.98      0.97      0.98      1178\n",
            "           9       0.96      0.96      0.96      1233\n",
            "\n",
            "    accuracy                           0.90     12000\n",
            "   macro avg       0.90      0.90      0.90     12000\n",
            "weighted avg       0.90      0.90      0.90     12000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1026    1   19   26    1    2   88    0    3    0]\n",
            " [   2 1188    2   14    2    0    5    0    0    0]\n",
            " [  19    0 1036   11   95    0   69    0    2    0]\n",
            " [  21    4    7 1101   39    0   34    0    3    0]\n",
            " [   2    0   67   28 1011    1   48    0    2    0]\n",
            " [   0    0    0    1    0 1179    0   24    0   13]\n",
            " [ 164    2   98   24   68    0  814    0    8    0]\n",
            " [   0    0    0    0    0    8    0 1169    2   36]\n",
            " [   3    1    3    5    2    0   15    3 1146    0]\n",
            " [   0    0    0    0    0    7    0   41    3 1182]]\n",
            "AUC Score: 0.9934571729426102\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'Logistic Regression': {'Confusion Matrix': array([[ 939,    8,   30,   59,    3,    2,  112,    1,   12,    0],\n",
              "         [   4, 1179,    5,   18,    2,    0,    4,    1,    0,    0],\n",
              "         [  22,    7,  896,    9,  170,    1,  121,    2,    4,    0],\n",
              "         [  30,   26,   14, 1038,   49,    0,   37,    0,   14,    1],\n",
              "         [   3,    1,   97,   35,  917,    4,   94,    1,    7,    0],\n",
              "         [   1,    3,    1,    1,    1, 1122,    1,   50,    6,   31],\n",
              "         [ 177,    9,  126,   50,  112,    1,  670,    0,   33,    0],\n",
              "         [   0,    0,    0,    0,    0,   39,    0, 1132,    5,   39],\n",
              "         [  12,    5,    8,   14,   12,    8,   33,    7, 1073,    6],\n",
              "         [   0,    0,    1,    0,    0,   30,    1,   52,    1, 1148]]),\n",
              "  'Classification Report': '              precision    recall  f1-score   support\\n\\n           0       0.79      0.81      0.80      1166\\n           1       0.95      0.97      0.96      1213\\n           2       0.76      0.73      0.74      1232\\n           3       0.85      0.86      0.85      1209\\n           4       0.72      0.79      0.76      1159\\n           5       0.93      0.92      0.93      1217\\n           6       0.62      0.57      0.60      1178\\n           7       0.91      0.93      0.92      1215\\n           8       0.93      0.91      0.92      1178\\n           9       0.94      0.93      0.93      1233\\n\\n    accuracy                           0.84     12000\\n   macro avg       0.84      0.84      0.84     12000\\nweighted avg       0.84      0.84      0.84     12000\\n',\n",
              "  'AUC Score': 0.9823389457900318,\n",
              "  'Cross-Validation Scores': array([0.83791667, 0.83135417, 0.83604167, 0.84447917, 0.84125   ]),\n",
              "  'Mean CV Score': 0.8382083333333334,\n",
              "  'Accuracy': 0.8428333333333333},\n",
              " 'Naive Bayes': {'Confusion Matrix': array([[ 674,   93,   33,  196,  125,    0,   20,    0,   25,    0],\n",
              "         [   2, 1153,   12,   33,    3,    0,    8,    0,    2,    0],\n",
              "         [   4,   22,  343,   61,  725,    0,   43,    0,   34,    0],\n",
              "         [  10,  560,    5,  582,   38,    0,   12,    0,    2,    0],\n",
              "         [   1,   63,   47,  159,  875,    0,    2,    0,   12,    0],\n",
              "         [   0,    1,    2,    2,    0,  312,    7,  821,   11,   61],\n",
              "         [ 139,   57,  136,  187,  557,    0,   50,    0,   52,    0],\n",
              "         [   0,    0,    0,    0,    0,    6,    0, 1189,    3,   17],\n",
              "         [   1,    6,   19,  102,  144,    7,   29,    4,  866,    0],\n",
              "         [   0,    0,    2,    1,    1,   22,    2,  407,    8,  790]]),\n",
              "  'Classification Report': '              precision    recall  f1-score   support\\n\\n           0       0.81      0.58      0.68      1166\\n           1       0.59      0.95      0.73      1213\\n           2       0.57      0.28      0.37      1232\\n           3       0.44      0.48      0.46      1209\\n           4       0.35      0.75      0.48      1159\\n           5       0.90      0.26      0.40      1217\\n           6       0.29      0.04      0.07      1178\\n           7       0.49      0.98      0.65      1215\\n           8       0.85      0.74      0.79      1178\\n           9       0.91      0.64      0.75      1233\\n\\n    accuracy                           0.57     12000\\n   macro avg       0.62      0.57      0.54     12000\\nweighted avg       0.62      0.57      0.54     12000\\n',\n",
              "  'AUC Score': 0.8866473364016987,\n",
              "  'Cross-Validation Scores': array([0.57375   , 0.56395833, 0.55947917, 0.57645833, 0.6021875 ]),\n",
              "  'Mean CV Score': 0.5751666666666666,\n",
              "  'Accuracy': 0.5695},\n",
              " 'KNN': {'Confusion Matrix': array([[1028,    1,   21,   25,    2,    0,   87,    0,    2,    0],\n",
              "         [   9, 1174,    4,   19,    2,    0,    5,    0,    0,    0],\n",
              "         [  28,    1,  963,   14,  143,    0,   82,    1,    0,    0],\n",
              "         [  51,   13,   15, 1046,   57,    0,   23,    0,    3,    1],\n",
              "         [   3,    0,  115,   30,  911,    0,   99,    0,    1,    0],\n",
              "         [   1,    0,    2,    1,    0, 1018,    4,  104,    1,   86],\n",
              "         [ 234,    2,  144,   18,   93,    0,  678,    0,    9,    0],\n",
              "         [   0,    0,    0,    0,    0,    3,    0, 1163,    0,   49],\n",
              "         [   9,    0,   18,    9,   11,    2,   28,    9, 1089,    3],\n",
              "         [   0,    0,    0,    0,    0,    4,    1,   40,    0, 1188]]),\n",
              "  'Classification Report': '              precision    recall  f1-score   support\\n\\n           0       0.75      0.88      0.81      1166\\n           1       0.99      0.97      0.98      1213\\n           2       0.75      0.78      0.77      1232\\n           3       0.90      0.87      0.88      1209\\n           4       0.75      0.79      0.77      1159\\n           5       0.99      0.84      0.91      1217\\n           6       0.67      0.58      0.62      1178\\n           7       0.88      0.96      0.92      1215\\n           8       0.99      0.92      0.95      1178\\n           9       0.90      0.96      0.93      1233\\n\\n    accuracy                           0.85     12000\\n   macro avg       0.86      0.85      0.85     12000\\nweighted avg       0.86      0.85      0.85     12000\\n',\n",
              "  'AUC Score': 0.9683621158401223,\n",
              "  'Cross-Validation Scores': array([0.8503125 , 0.84875   , 0.85072917, 0.85270833, 0.850625  ]),\n",
              "  'Mean CV Score': 0.850625,\n",
              "  'Accuracy': 0.8548333333333333},\n",
              " 'SVM': {'Confusion Matrix': array([[1008,    0,   18,   44,    1,    0,   85,    0,   10,    0],\n",
              "         [   5, 1184,    1,   16,    1,    0,    3,    0,    3,    0],\n",
              "         [  14,    0,  995,   13,  120,    0,   83,    0,    7,    0],\n",
              "         [  24,    8,    7, 1092,   47,    0,   25,    0,    6,    0],\n",
              "         [   1,    0,   74,   34,  990,    0,   57,    0,    3,    0],\n",
              "         [   0,    0,    0,    1,    0, 1155,    0,   39,    7,   15],\n",
              "         [ 177,    1,  101,   27,   71,    0,  776,    0,   25,    0],\n",
              "         [   0,    0,    0,    0,    0,   16,    0, 1167,    2,   30],\n",
              "         [   3,    0,    5,    9,    5,    2,   12,    2, 1140,    0],\n",
              "         [   0,    0,    0,    0,    0,   19,    0,   44,    5, 1165]]),\n",
              "  'Classification Report': '              precision    recall  f1-score   support\\n\\n           0       0.82      0.86      0.84      1166\\n           1       0.99      0.98      0.98      1213\\n           2       0.83      0.81      0.82      1232\\n           3       0.88      0.90      0.89      1209\\n           4       0.80      0.85      0.83      1159\\n           5       0.97      0.95      0.96      1217\\n           6       0.75      0.66      0.70      1178\\n           7       0.93      0.96      0.95      1215\\n           8       0.94      0.97      0.96      1178\\n           9       0.96      0.94      0.95      1233\\n\\n    accuracy                           0.89     12000\\n   macro avg       0.89      0.89      0.89     12000\\nweighted avg       0.89      0.89      0.89     12000\\n',\n",
              "  'AUC Score': 0.9914782198437321,\n",
              "  'Cross-Validation Scores': array([0.88854167, 0.88947917, 0.8859375 , 0.88979167, 0.88770833]),\n",
              "  'Mean CV Score': 0.8882916666666667,\n",
              "  'Accuracy': 0.8893333333333333},\n",
              " 'Gradient Boosting': {'Confusion Matrix': array([[ 972,    3,   18,   54,    1,    1,  108,    0,    9,    0],\n",
              "         [   9, 1182,    3,   17,    1,    0,    1,    0,    0,    0],\n",
              "         [  15,    1,  992,   11,  131,    1,   73,    0,    8,    0],\n",
              "         [  28,    6,   12, 1072,   50,    0,   38,    0,    3,    0],\n",
              "         [   2,    0,   92,   40,  955,    0,   65,    0,    5,    0],\n",
              "         [   1,    0,    0,    0,    0, 1152,    0,   39,    4,   21],\n",
              "         [ 188,    3,  117,   28,  108,    0,  720,    0,   14,    0],\n",
              "         [   0,    0,    0,    0,    0,   12,    0, 1156,    2,   45],\n",
              "         [   0,    1,    3,    7,   11,    6,   25,    3, 1122,    0],\n",
              "         [   0,    0,    0,    0,    0,    9,    0,   57,    2, 1165]]),\n",
              "  'Classification Report': '              precision    recall  f1-score   support\\n\\n           0       0.80      0.83      0.82      1166\\n           1       0.99      0.97      0.98      1213\\n           2       0.80      0.81      0.80      1232\\n           3       0.87      0.89      0.88      1209\\n           4       0.76      0.82      0.79      1159\\n           5       0.98      0.95      0.96      1217\\n           6       0.70      0.61      0.65      1178\\n           7       0.92      0.95      0.94      1215\\n           8       0.96      0.95      0.96      1178\\n           9       0.95      0.94      0.95      1233\\n\\n    accuracy                           0.87     12000\\n   macro avg       0.87      0.87      0.87     12000\\nweighted avg       0.87      0.87      0.87     12000\\n',\n",
              "  'AUC Score': 0.9895500277675229,\n",
              "  'Cross-Validation Scores': array([0.8684375 , 0.87197917, 0.86677083, 0.87791667, 0.87572917]),\n",
              "  'Mean CV Score': 0.8721666666666665,\n",
              "  'Accuracy': 0.874},\n",
              " 'Random Forest': {'Confusion Matrix': array([[1001,    0,   19,   50,    2,    1,   85,    0,    8,    0],\n",
              "         [   5, 1173,    1,   27,    0,    0,    7,    0,    0,    0],\n",
              "         [   5,    1,  992,   11,  144,    0,   71,    0,    8,    0],\n",
              "         [  21,    3,   14, 1103,   37,    0,   26,    0,    5,    0],\n",
              "         [   1,    1,   79,   34,  993,    0,   49,    0,    2,    0],\n",
              "         [   0,    0,    0,    0,    0, 1172,    0,   32,    1,   12],\n",
              "         [ 199,    1,  128,   25,  110,    0,  701,    0,   14,    0],\n",
              "         [   0,    0,    0,    0,    0,   13,    0, 1146,    1,   55],\n",
              "         [   2,    0,    4,    5,    6,    1,   13,    4, 1142,    1],\n",
              "         [   0,    0,    0,    0,    0,   17,    0,   47,    1, 1168]]),\n",
              "  'Classification Report': '              precision    recall  f1-score   support\\n\\n           0       0.81      0.86      0.83      1166\\n           1       0.99      0.97      0.98      1213\\n           2       0.80      0.81      0.80      1232\\n           3       0.88      0.91      0.90      1209\\n           4       0.77      0.86      0.81      1159\\n           5       0.97      0.96      0.97      1217\\n           6       0.74      0.60      0.66      1178\\n           7       0.93      0.94      0.94      1215\\n           8       0.97      0.97      0.97      1178\\n           9       0.94      0.95      0.95      1233\\n\\n    accuracy                           0.88     12000\\n   macro avg       0.88      0.88      0.88     12000\\nweighted avg       0.88      0.88      0.88     12000\\n',\n",
              "  'AUC Score': 0.9902691492979866,\n",
              "  'Cross-Validation Scores': array([0.874375  , 0.88072917, 0.8759375 , 0.8825    , 0.87802083]),\n",
              "  'Mean CV Score': 0.8783125,\n",
              "  'Accuracy': 0.8825833333333334},\n",
              " 'XGBoost': {'Confusion Matrix': array([[1026,    1,   19,   26,    1,    2,   88,    0,    3,    0],\n",
              "         [   2, 1188,    2,   14,    2,    0,    5,    0,    0,    0],\n",
              "         [  19,    0, 1036,   11,   95,    0,   69,    0,    2,    0],\n",
              "         [  21,    4,    7, 1101,   39,    0,   34,    0,    3,    0],\n",
              "         [   2,    0,   67,   28, 1011,    1,   48,    0,    2,    0],\n",
              "         [   0,    0,    0,    1,    0, 1179,    0,   24,    0,   13],\n",
              "         [ 164,    2,   98,   24,   68,    0,  814,    0,    8,    0],\n",
              "         [   0,    0,    0,    0,    0,    8,    0, 1169,    2,   36],\n",
              "         [   3,    1,    3,    5,    2,    0,   15,    3, 1146,    0],\n",
              "         [   0,    0,    0,    0,    0,    7,    0,   41,    3, 1182]]),\n",
              "  'Classification Report': '              precision    recall  f1-score   support\\n\\n           0       0.83      0.88      0.85      1166\\n           1       0.99      0.98      0.99      1213\\n           2       0.84      0.84      0.84      1232\\n           3       0.91      0.91      0.91      1209\\n           4       0.83      0.87      0.85      1159\\n           5       0.98      0.97      0.98      1217\\n           6       0.76      0.69      0.72      1178\\n           7       0.95      0.96      0.95      1215\\n           8       0.98      0.97      0.98      1178\\n           9       0.96      0.96      0.96      1233\\n\\n    accuracy                           0.90     12000\\n   macro avg       0.90      0.90      0.90     12000\\nweighted avg       0.90      0.90      0.90     12000\\n',\n",
              "  'AUC Score': 0.9934571729426102,\n",
              "  'Cross-Validation Scores': array([0.89760417, 0.895625  , 0.89791667, 0.90083333, 0.89989583]),\n",
              "  'Mean CV Score': 0.898375,\n",
              "  'Accuracy': 0.9043333333333333}}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "fashion_mnist_data = pd.read_csv('data/mnist_fashion_train.csv')\n",
        "\n",
        "y = fashion_mnist_data['label']\n",
        "X = scale(fashion_mnist_data.drop(['label'], axis=1))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=10000, random_state=1),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'SVM': SVC(probability=True, random_state=1),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(random_state=1),\n",
        "    'Random Forest': RandomForestClassifier(class_weight='balanced', random_state=1),\n",
        "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=1)\n",
        "}\n",
        "\n",
        "# Evaluate models using cross-validation\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    auc_score = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr')\n",
        "\n",
        "    results[name] = {\n",
        "        'Confusion Matrix': conf_matrix,\n",
        "        'Classification Report': report,\n",
        "        'AUC Score': auc_score,\n",
        "        'Cross-Validation Scores': cv_scores,\n",
        "        'Mean CV Score': cv_scores.mean(),\n",
        "        'Accuracy': accuracy\n",
        "    }\n",
        "\n",
        "    print(f'--- {name} ---')\n",
        "    print(f'Cross-Validation Scores: {cv_scores}')\n",
        "    print(f'Mean CV Score: {cv_scores.mean()}')\n",
        "    print(f'Accuracy: {accuracy}')\n",
        "    print(f'Classification Report:\\n{report}')\n",
        "    print(f'Confusion Matrix:\\n{conf_matrix}')\n",
        "    print(f'AUC Score: {auc_score}')\n",
        "    print()\n",
        "\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kb0wdKpLb3tX"
      },
      "source": [
        "## Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTuWRST2b3tX"
      },
      "source": [
        "https://www.makariev.com/blog/fashion-MNIST-in-csv/\n",
        "\n",
        "| Label | Description  |\n",
        "|-------|--------------|\n",
        "| 0     | T-shirt/top  |\n",
        "| 1     | Trouser      |\n",
        "| 2     | Pullover     |\n",
        "| 3     | Dress        |\n",
        "| 4     | Coat         |\n",
        "| 5     | Sandal       |\n",
        "| 6     | Shirt        |\n",
        "| 7     | Sneaker      |\n",
        "| 8     | Bag          |\n",
        "| 9     | Ankle boot   |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlHoTqKOb3tX"
      },
      "source": [
        "## Using pyTorch\n",
        "\n",
        "why did I normalize the pixel values? my reference\n",
        "\n",
        "https://stackoverflow.com/questions/63746182/correct-way-of-normalizing-and-scaling-the-mnist-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eh8WXg8hb3tX"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "fashion_mnist_data = pd.read_csv('mnist_fashion_train.csv')\n",
        "\n",
        "y = fashion_mnist_data['label'].ravel()\n",
        "X = scale(fashion_mnist_data.drop(['label'], axis=1))\n",
        "\n",
        "print('Min Pixel Value: {} \\nMax Pixel Value: {}'.format(trainset.data.min(), trainset.data.max()))\n",
        "print('Mean Pixel Value {} \\nPixel Values Std: {}'.format(trainset.data.float().mean(), trainset.data.float().std()))\n",
        "print('Scaled Mean Pixel Value {} \\nScaled Pixel Values Std: {}'.format(trainset.data.float().mean() / 255, trainset.data.float().std() / 255))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('./data', train=True\n",
        "        transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((trainset.data.float().mean() / 255,), (trainset.data.float().std(),))\n",
        "        ])),"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJLIBl0Db3tY"
      },
      "source": [
        "Applied into complete code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1i3y-dhb3tY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "fashion_mnist_data = pd.read_csv('mnist_fashion_train.csv')\n",
        "\n",
        "y = fashion_mnist_data['label'].values\n",
        "X = fashion_mnist_data.drop(['label'], axis=1).values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).reshape(-1, 1, 28, 28)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).reshape(-1, 1, 28, 28)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "mean = X_train_tensor.mean().item()\n",
        "std = X_train_tensor.std().item()\n",
        "\n",
        "# Apply transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Normalize((mean,), (std,))\n",
        "])\n",
        "\n",
        "# Create custom dataset to apply transforms\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, labels, transform=None):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "        return sample, self.labels[idx]\n",
        "\n",
        "# Create DataLoader\n",
        "train_dataset = CustomDataset(X_train_tensor, y_train_tensor, transform=transform)\n",
        "test_dataset = CustomDataset(X_test_tensor, y_test_tensor, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Define the Neural Network\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)  # 10 classes for Fashion-MNIST\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten the input\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training the model\n",
        "num_epochs = 50\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluating the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_test_pred_scores = model(X_test_tensor.to(device)).cpu()\n",
        "    y_test_pred_class = torch.argmax(y_test_pred_scores, dim=1)\n",
        "\n",
        "report = classification_report(y_test, y_test_pred_class.numpy(), target_names=[\n",
        "    \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"\n",
        "])\n",
        "\n",
        "# Convert y_test to one-hot encoding\n",
        "y_test_one_hot = label_binarize(y_test, classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "\n",
        "roc_auc = roc_auc_score(y_test_one_hot, y_test_pred_scores.numpy(), multi_class='ovr')\n",
        "\n",
        "output_text = (\n",
        "    \"Final Model Classification Report:\\n\" + report + \"\\n\" +\n",
        "    f\"Final Model ROC AUC Score: {roc_auc:.4f}\"\n",
        ")\n",
        "\n",
        "print(output_text)\n",
        "\n",
        "with open(\"model_evaluation_torch_fashion_mnist.txt\", \"w\") as file:\n",
        "    file.write(output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKhm5BAbb3tY"
      },
      "source": [
        "**Output**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMGrhytRb3tZ"
      },
      "source": [
        "Final Model Classification Report (PyTorch):\n",
        "```\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        " T-shirt/top       0.81      0.85      0.83      1769\n",
        "     Trouser       0.99      0.98      0.98      1835\n",
        "    Pullover       0.83      0.78      0.80      1801\n",
        "       Dress       0.87      0.90      0.89      1789\n",
        "        Coat       0.80      0.83      0.81      1815\n",
        "      Sandal       0.97      0.95      0.96      1783\n",
        "       Shirt       0.73      0.69      0.71      1811\n",
        "     Sneaker       0.95      0.91      0.93      1759\n",
        "         Bag       0.96      0.96      0.96      1825\n",
        "  Ankle boot       0.92      0.97      0.95      1813\n",
        "\n",
        "    accuracy                           0.88     18000\n",
        "   macro avg       0.88      0.88      0.88     18000\n",
        "weighted avg       0.88      0.88      0.88     18000\n",
        "```\n",
        "\n",
        "Final Model ROC AUC Score (PyTorch): 0.9840"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqsDHa8Cb3tZ"
      },
      "source": [
        "Both MLPClassifier and pyTorch are Neural Networks (supervised) , but their flexibility is different. Now I will apply MLPClassifier into same code and will compare their speed, and performance. Also, I will apply cross-valudation for both method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UA_GadVEb3tZ"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import numpy as np  # Add this import\n",
        "\n",
        "fashion_mnist_data = pd.read_csv('mnist_fashion_train.csv')\n",
        "\n",
        "y = fashion_mnist_data['label'].values\n",
        "X = fashion_mnist_data.drop(['label'], axis=1).values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Define the Neural Network for PyTorch\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(X.shape[1], 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)  # 10 classes for Fashion-MNIST\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Cross-validation for PyTorch model\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "pytorch_cv_scores = []\n",
        "\n",
        "for train_index, val_index in kf.split(X):\n",
        "    X_train, X_val = X[train_index], X[val_index]\n",
        "    y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
        "    y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
        "\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    model_torch = NeuralNetwork().to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model_torch.parameters(), lr=0.001)\n",
        "\n",
        "    # Training the model\n",
        "    num_epochs = 50\n",
        "    model_torch.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model_torch(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Evaluating the model\n",
        "    model_torch.eval()\n",
        "    with torch.no_grad():\n",
        "        y_val_pred = model_torch(X_val_tensor.to(device)).cpu()\n",
        "        y_val_pred_class = torch.argmax(y_val_pred, dim=1)\n",
        "        accuracy = accuracy_score(y_val, y_val_pred_class.numpy())\n",
        "        pytorch_cv_scores.append(accuracy)\n",
        "\n",
        "print(f\"Cross-Validation Scores (PyTorch): {pytorch_cv_scores}\")\n",
        "print(f\"Mean Cross-Validation Score (PyTorch): {np.mean(pytorch_cv_scores):.4f}\")\n",
        "\n",
        "# Train final PyTorch model on full training data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "model_torch = NeuralNetwork().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_torch.parameters(), lr=0.001)\n",
        "\n",
        "print(\"Training final PyTorch Model...\")\n",
        "start_time = time.time()\n",
        "model_torch.train()\n",
        "for epoch in range(num_epochs):\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model_torch(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "end_time = time.time()\n",
        "pytorch_training_time = end_time - start_time\n",
        "print(f\"PyTorch Model Training Time: {pytorch_training_time:.2f} seconds\")\n",
        "\n",
        "# Evaluating the final PyTorch model\n",
        "model_torch.eval()\n",
        "with torch.no_grad():\n",
        "    y_test_pred = model_torch(X_test_tensor.to(device)).cpu()\n",
        "    y_test_pred_class = torch.argmax(y_test_pred, dim=1)\n",
        "\n",
        "report = classification_report(y_test, y_test_pred_class.numpy(), target_names=[\n",
        "    \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"\n",
        "])\n",
        "\n",
        "# Calculate ROC AUC score using raw prediction scores\n",
        "roc_auc = roc_auc_score(pd.get_dummies(y_test), y_test_pred.numpy(), multi_class='ovr')\n",
        "\n",
        "output_text = (\n",
        "    \"Final Model Classification Report (PyTorch):\\n\" + report + \"\\n\" +\n",
        "    f\"Final Model ROC AUC Score (PyTorch): {roc_auc:.4f}\"\n",
        ")\n",
        "\n",
        "print(output_text)\n",
        "\n",
        "with open(\"model_evaluation_torch.txt\", \"w\") as file:\n",
        "    file.write(output_text)\n",
        "\n",
        "# Cross-validation for scikit-learn MLPClassifier\n",
        "print(\"Training scikit-learn MLPClassifier with cross-validation...\")\n",
        "mlp_clf = MLPClassifier(max_iter=500, random_state=1, hidden_layer_sizes=(100,100))\n",
        "sklearn_cv_scores = cross_val_score(mlp_clf, X, y, cv=5)\n",
        "\n",
        "print(f\"Cross-Validation Scores (scikit-learn MLPClassifier): {sklearn_cv_scores}\")\n",
        "print(f\"Mean Cross-Validation Score (scikit-learn MLPClassifier): {np.mean(sklearn_cv_scores):.4f}\")\n",
        "\n",
        "print(\"Training final scikit-learn MLPClassifier...\")\n",
        "start_time = time.time()\n",
        "mlp_clf.fit(X_train, y_train)\n",
        "y_test_pred_sk = mlp_clf.predict(X_test)\n",
        "end_time = time.time()\n",
        "\n",
        "sklearn_training_time = end_time - start_time\n",
        "print(f\"scikit-learn MLPClassifier Training Time: {sklearn_training_time:.2f} seconds\")\n",
        "\n",
        "report_sk = classification_report(y_test, y_test_pred_sk, target_names=[\n",
        "    \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"\n",
        "])\n",
        "\n",
        "print(\"Classification Report (scikit-learn MLPClassifier):\")\n",
        "print(report_sk)\n",
        "\n",
        "with open(\"model_evaluation_sklearn.txt\", \"w\") as file:\n",
        "    file.write(\"Final Model Classification Report (scikit-learn MLPClassifier):\\n\" + report_sk)\n",
        "\n",
        "print(f\"PyTorch Model Training Time: {pytorch_training_time:.2f} seconds\")\n",
        "print(f\"scikit-learn MLPClassifier Training Time: {sklearn_training_time:.2f} seconds\")\n",
        "print(f\"Cross-Validation Scores (PyTorch): {pytorch_cv_scores}\")\n",
        "print(f\"Mean Cross-Validation Score (PyTorch): {np.mean(pytorch_cv_scores):.4f}\")\n",
        "print(f\"Cross-Validation Scores (scikit-learn MLPClassifier): {sklearn_cv_scores}\")\n",
        "print(f\"Mean Cross-Validation Score (scikit-learn MLPClassifier): {np.mean(sklearn_cv_scores):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JKuDIKzb3ta"
      },
      "source": [
        "**Output**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdpOdF--b3ta"
      },
      "source": [
        "Cross-Validation Scores (PyTorch): [0.8876666666666667, 0.8835, 0.8910833333333333, 0.8845833333333334, 0.8860833333333333]\\\n",
        "Mean Cross-Validation Score (PyTorch): 0.8866\\\n",
        "Training final PyTorch Model...\\\n",
        "Epoch [10/50], Loss: 0.1090\\\n",
        "Epoch [20/50], Loss: 0.1071\\\n",
        "Epoch [30/50], Loss: 0.0946\\\n",
        "Epoch [40/50], Loss: 0.0101\\\n",
        "Epoch [50/50], Loss: 0.3497\\\n",
        "PyTorch Model Training Time: 249.59 seconds\\\n",
        "\n",
        "\n",
        "\n",
        "Final Model Classification Report (PyTorch):\n",
        "```\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        " T-shirt/top       0.81      0.85      0.83      1769\n",
        "     Trouser       0.99      0.98      0.98      1835\n",
        "    Pullover       0.83      0.78      0.80      1801\n",
        "       Dress       0.87      0.90      0.89      1789\n",
        "        Coat       0.80      0.83      0.81      1815\n",
        "      Sandal       0.97      0.95      0.96      1783\n",
        "       Shirt       0.73      0.69      0.71      1811\n",
        "     Sneaker       0.95      0.91      0.93      1759\n",
        "         Bag       0.96      0.96      0.96      1825\n",
        "  Ankle boot       0.92      0.97      0.95      1813\n",
        "\n",
        "    accuracy                           0.88     18000\n",
        "   macro avg       0.88      0.88      0.88     18000\n",
        "weighted avg       0.88      0.88      0.88     18000\n",
        "```\n",
        "\n",
        "Final Model ROC AUC Score (PyTorch): 0.9840\\\n",
        "Training scikit-learn MLPClassifier with cross-validation...\\\n",
        "Cross-Validation Scores (scikit-learn MLPClassifier): [0.88908333 0.88383333 0.8875     0.88741667 0.883     ]\\\n",
        "Mean Cross-Validation Score (scikit-learn MLPClassifier): 0.8862\\\n",
        "Training final scikit-learn MLPClassifier...\\\n",
        "scikit-learn MLPClassifier Training Time: 161.56 seconds\n",
        "\n",
        "\n",
        "Classification Report (scikit-learn MLPClassifier):\n",
        "```\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        " T-shirt/top       0.84      0.84      0.84      1769\n",
        "     Trouser       0.98      0.98      0.98      1835\n",
        "    Pullover       0.75      0.87      0.81      1801\n",
        "       Dress       0.87      0.92      0.89      1789\n",
        "        Coat       0.85      0.76      0.80      1815\n",
        "      Sandal       0.96      0.96      0.96      1783\n",
        "       Shirt       0.76      0.68      0.72      1811\n",
        "     Sneaker       0.94      0.95      0.94      1759\n",
        "         Bag       0.97      0.96      0.96      1825\n",
        "  Ankle boot       0.95      0.96      0.96      1813\n",
        "\n",
        "    accuracy                           0.89     18000\n",
        "   macro avg       0.89      0.89      0.89     18000\n",
        "weighted avg       0.89      0.89      0.89     18000\n",
        "\n",
        "```\n",
        "PyTorch Model Training Time: 249.59 seconds\\\n",
        "scikit-learn MLPClassifier Training Time: 161.56 seconds\\\n",
        "Cross-Validation Scores (PyTorch): [0.8876666666666667, 0.8835, 0.8910833333333333, 0.8845833333333334, 0.8860833333333333]\\\n",
        "Mean Cross-Validation Score (PyTorch): 0.8866\\\n",
        "Cross-Validation Scores (scikit-learn MLPClassifier): [0.88908333 0.88383333 0.8875     0.88741667 0.883     ]\\\n",
        "Mean Cross-Validation Score (scikit-learn MLPClassifier): 0.8862"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AICP0Zyvb3ta"
      },
      "source": [
        "### Deep Neural Networks with MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_bsM8ynb3ta",
        "outputId": "2570128f-1df6-42d6-af56-b0c0fe01490c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report (Deep Neural Network):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.84      0.83      1166\n",
            "           1       0.98      0.99      0.98      1213\n",
            "           2       0.81      0.80      0.81      1232\n",
            "           3       0.91      0.88      0.89      1209\n",
            "           4       0.79      0.86      0.82      1159\n",
            "           5       0.96      0.95      0.96      1217\n",
            "           6       0.75      0.70      0.72      1178\n",
            "           7       0.93      0.95      0.94      1215\n",
            "           8       0.97      0.96      0.96      1178\n",
            "           9       0.95      0.95      0.95      1233\n",
            "\n",
            "    accuracy                           0.89     12000\n",
            "   macro avg       0.89      0.89      0.89     12000\n",
            "weighted avg       0.89      0.89      0.89     12000\n",
            "\n",
            "Cross-Valudation score: [0.88316667 0.88241667 0.88883333 0.88941667 0.88783333]\n",
            "CPU times: user 10min 48s, sys: 1min 7s, total: 11min 55s\n",
            "Wall time: 6min 1s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "mdlDncDgt = MLPClassifier(hidden_layer_sizes=(100,100))\n",
        "mdlDncDgt.fit(X_train, y_train)\n",
        "y_test_pred = mdlDncDgt.predict(X_test)\n",
        "\n",
        "print ('Classification Report (Deep Neural Network):')\n",
        "print (classification_report(y_test, y_test_pred))\n",
        "\n",
        "print(\"Cross-Valudation score: {}\".format(cross_val_score(mdlDncDgt, X, y, cv=5)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gw1Y06bhb3tb",
        "outputId": "74e90860-5de6-482d-e95f-bb7cf5d7580a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC AUC score: 0.9904081526994275\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "y_test_prob = mdlDncDgt.predict_proba(X_test)\n",
        "roc_auc = roc_auc_score(y_test, y_test_prob, multi_class='ovr')\n",
        "print(\"ROC AUC score: {}\".format(roc_auc))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scikit-learn's `MLPClassifier` requires less code for defining the model and training loop, on the other hand PyTorch offers more flexibility in defining custom neural networks but requires more detailed implementation of the training process. From the code we have seen MLPClassifier works faster, and Cross-Validation Scores a little bit better. It may due to my inadequency in applying PyTorch Neural Networks, because at the end both uses same algorithms.(Both can represent multi-layer perceptrons (MLPs) with various hidden layers and neurons. Also both use backpropagation to compute gradients and update weights and both involve forward passes to compute predictions and backward passes to update model parameters based on the loss function.)"
      ],
      "metadata": {
        "id": "orxzp2KLcCYy"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}